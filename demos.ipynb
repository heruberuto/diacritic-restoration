{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diacritics restoration demos\n",
    "This sheet should serve as a set of universal usage examples for the basic diacritics restoration-related tasks. It will cover the main functions of module diacritics_restorer.py and some of accents.py\n",
    "\n",
    "## 0. Modules import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready.\n"
     ]
    }
   ],
   "source": [
    "import diacritics_restorer as dr\n",
    "import accents\n",
    "print(\"ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using the accents module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cele sprezeni vezelo ve snehu jako v hrobe.\n",
      "čómpôşë\n",
      "[('c', 'ˇ'), ('o', '´'), ('m', ' '), ('p', ' '), ('o', 'ˆ'), ('s', '¸'), ('e', '¨')]\n"
     ]
    }
   ],
   "source": [
    "stripped_string = accents.strip(\"Celé spřežení vězelo ve sněhu jako v hrobě.\") #strip accents\n",
    "print(stripped_string)\n",
    "composed_string = accents.compose([(\"c\",accents.CARON),(\"o\",accents.ACUTE),(\"m\",accents.NO_ACCENT), # compose accents with letters\n",
    "                       (\"p\",accents.NO_ACCENT),(\"o\",accents.CIRCUMFLEX),(\"s\",accents.CEDILLA),(\"e\",accents.UMLAUT),])\n",
    "print(composed_string)\n",
    "print([accents.decompose(character) for character in composed_string]) # decompose dia-characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using the diacritics_restorer module\n",
    "The following scripts are here just to show how to instantiate the diacritics restorer training, testing and how to save the pre-trained models. The training set (Project Gutenberg collection of František Omelka) is way too small to give observations to restore much else than itself. For more impressive instances, scroll down.\n",
    "### 2.1 Buffering a corpus file as a (n-gram,tag) couples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUFFERED line #0 of corpora/simple.txt - \"Valašsko Tichý a zadumaný kraj\"\n",
      "[('V', ' '), ('Va', ' '), ('Val', ' '), ('ala', ' '), ('las', 'ˇ'), ('ass', ' '), ('ssk', ' '), ('sko', ' '), ('ko ', ' '), ('o T', ' '), (' Ti', ' '), ('Tic', ' '), ('ich', ' '), ('chy', '´'), ('hy ', ' '), ('y a', ' '), (' a ', ' '), ('a z', ' '), (' za', ' '), ('zad', ' '), ('adu', ' '), ('dum', ' '), ('uma', ' '), ('man', ' '), ('any', '´'), ('ny ', ' '), ('y k', ' '), (' kr', ' '), ('kra', ' '), ('raj', ' ')]\n"
     ]
    }
   ],
   "source": [
    "buf = dr.CorpusNgramBuffer(\"corpora/simple.txt\",3,1)\n",
    "print(buf.__next__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUFFERED line #0 of corpora/simple.txt - \"Valašsko Tichý a zadumaný kraj\"\n",
      "training done: 7.349462032318115\n"
     ]
    }
   ],
   "source": [
    "simple_hmm = dr.HmmNgramRestorer(4).train(\"corpora/simple.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Accent restoration\n",
    "Let us use the stripped sentence from example #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Celé spřežení vezelo ve sněhu jako v hrobe.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_hmm.restore_accents(stripped_string) # uses stripped_string from #1 above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Accuracy testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUFFERED line #0 of corpora/simple_test.txt - \"Seppala se rozhlédl.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9200923279841724,\n",
       " 'correct': 33484,\n",
       " 'incorrect': 2908,\n",
       " 'word_accuracy': 0.6385522436947265,\n",
       " 'words_correct': 3899,\n",
       " 'words_incorrect': 2207,\n",
       " 'diaword_accuracy': 0.2735648476257973,\n",
       " 'diawords_correct': 772,\n",
       " 'diawords_incorrect': 2050,\n",
       " 'alphaword_accuracy': 0.6343605036447979,\n",
       " 'alphawords_correct': 3829,\n",
       " 'alphawords_incorrect': 2207}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_hmm.test(\"corpora/simple_test.txt\").as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Serialization - Saving to and loading from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Celé spřežení vezelo ve sněhu jako v hrobe.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_hmm.save(\"pretrained/simple.pickle\")\n",
    "simple_hmm2 = dr.HmmNgramRestorer.load(\"pretrained/simple.pickle\")\n",
    "simple_hmm2.restore_accents(stripped_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Use a pretrained HMM on a custom sentence\n",
    "Note that for the quality of restoration, we are often using n-grams of size $n>4$, that were omitted from the submissions. They can be downloaded at http://herbert.saarland/pretrained.zip\n",
    "### 3.1 Croatian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready.\n"
     ]
    }
   ],
   "source": [
    "hmm_hr = dr.HmmNgramRestorer.load(\"pretrained/hr/5-gram.pickle\")\n",
    "print(\"ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'boskovićev uspjeh slave tri države: hrvatska, italija i srbija.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_hr.restore_accents(accents.strip(\"boškovićev uspjeh slave tri države: hrvatska, italija i srbija.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'američko državljanstvo vraćeno mu je postumno odlukom američkog senata 1975. godine.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_hr.restore_accents(accents.strip(\"američko državljanstvo vraćeno mu je postumno odlukom američkog senata 1975. godine.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Irish Gaellic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready.\n"
     ]
    }
   ],
   "source": [
    "hmm_ga = dr.HmmNgramRestorer.load(\"pretrained/ga/8-gram.pickle\")\n",
    "print(\"ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ba éarnail thabhachtach den gheilleagar e an mhianadoireacht.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_ga.restore_accents(\"ba earnail thabhachtach den gheilleagar e an mhianadoireacht.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bhí sé go tréan ag cur catha ar a chomharsana san oirthear.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_ga.restore_accents(accents.strip(\"bhí sé go tréan ag cur catha ar a chomharsana san oirthear.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Czech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready.\n"
     ]
    }
   ],
   "source": [
    "hmm_cs = dr.HmmNgramRestorer.load(\"pretrained/cs/6-gram.pickle\")\n",
    "print(\"ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'velmi tmavý povrch komet jim dovoluje absorbovat teplo potřebné na jejích odplynování.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_cs.restore_accents(accents.strip('velmi tmavý povrch komet jim dovoluje absorbovat teplo potřebné na jejich odplynování.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'další významně pozorovaní kometarního rozpadu byl dopad komety shoemaker-levy 9, pozorovany roku 1993.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_cs.restore_accents(\"dalsi vyznamne pozorovani kometarniho rozpadu byl dopad komety shoemaker-levy 9, pozorovany roku 1993.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Slovakian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready.\n"
     ]
    }
   ],
   "source": [
    "hmm_sk = dr.HmmNgramRestorer.load(\"pretrained/sk/6-gram.pickle\")\n",
    "print(\"ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'j. lenoir skonštruoval v roku 1860 dvojtaktný dvojčinný posuvačový motor na svietiplyn.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_sk.restore_accents(accents.strip(\"j. lenoir skonštruoval v roku 1860 dvojtaktný dvojčinný posúvačový motor na svietiplyn.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Hungarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready.\n"
     ]
    }
   ],
   "source": [
    "hmm_hu = dr.HmmNgramRestorer.load(\"pretrained/hu/6-gram.pickle\")\n",
    "print(\"ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alexiosz igéretet tett rá, hogy fedezi az egyiptomba induló kéresztésék költségeit, ha eluzik bitorló nagybátyjat.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_hu.restore_accents(accents.strip(\"alexiosz ígéretet tett rá, hogy fedezi az egyiptomba induló keresztesek költségeit, ha elűzik bitorló nagybátyját.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready.\n"
     ]
    }
   ],
   "source": [
    "hmm_fr = dr.HmmNgramRestorer.load(\"pretrained/fr/4-gram.pickle\")\n",
    "print(\"ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'les conditions metéorologiques sont très mauvaises entre avril 1315 et avril 1316.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_fr.restore_accents(accents.strip(\"les conditions météorologiques sont très mauvaises entre avril 1315 et avril 1316.\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
